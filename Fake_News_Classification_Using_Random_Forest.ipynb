{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6641062,
          "sourceType": "datasetVersion",
          "datasetId": 2093157
        }
      ],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Fake News Classification Using Random Forest",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayubarslaan/Fake-News-Classification/blob/main/Fake_News_Classification_Using_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "saurabhshahane_fake_news_classification_path = kagglehub.dataset_download('saurabhshahane/fake-news-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "JBWtGdVGSeZc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries and observe input folders in Kaggle notebook"
      ],
      "metadata": {
        "id": "hq2yxiSHSeZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear algebra\n",
        "import numpy as np\n",
        "\n",
        "# Data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import subprocess\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Download and unzip wordnet\n",
        "try:\n",
        "    nltk.data.find('wordnet.zip')\n",
        "except:\n",
        "    nltk.download('wordnet', download_dir='/kaggle/working/')\n",
        "    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n",
        "    subprocess.run(command.split())\n",
        "    nltk.data.path.append('/kaggle/working/')\n",
        "\n",
        "# Now you can import the NLTK resources as usual\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"The TensorFlow version is: \", tf.__version__)\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM,Bidirectional\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Observe input folders in Kaggle notebook\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:35.258492Z",
          "iopub.execute_input": "2024-01-16T15:35:35.259293Z",
          "iopub.status.idle": "2024-01-16T15:35:53.024524Z",
          "shell.execute_reply.started": "2024-01-16T15:35:35.259255Z",
          "shell.execute_reply": "2024-01-16T15:35:53.023561Z"
        },
        "trusted": true,
        "id": "WN2DzEo-SeZk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read WELFake_Dataset.csv from kaggle/input"
      ],
      "metadata": {
        "id": "EgDjaVPLSeZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read WELFake_Dataset.csv from kaggle/input\n",
        "df = pd.read_csv(\"/kaggle/input/fake-news-classification/WELFake_Dataset.csv\")\n",
        "# Show first 5 rows of Dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:53.026083Z",
          "iopub.execute_input": "2024-01-16T15:35:53.026678Z",
          "iopub.status.idle": "2024-01-16T15:35:59.025649Z",
          "shell.execute_reply.started": "2024-01-16T15:35:53.026647Z",
          "shell.execute_reply": "2024-01-16T15:35:59.024647Z"
        },
        "trusted": true,
        "id": "0P9HMRZiSeZm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA(Exploratory Data Analysis)"
      ],
      "metadata": {
        "id": "DuFtUpdfSeZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.026917Z",
          "iopub.execute_input": "2024-01-16T15:35:59.027315Z",
          "iopub.status.idle": "2024-01-16T15:35:59.074324Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.027279Z",
          "shell.execute_reply": "2024-01-16T15:35:59.073428Z"
        },
        "trusted": true,
        "id": "bzmYPtYfSeZn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing data analysis"
      ],
      "metadata": {
        "id": "k5twWccHSeZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing data analysis\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.076827Z",
          "iopub.execute_input": "2024-01-16T15:35:59.077121Z",
          "iopub.status.idle": "2024-01-16T15:35:59.099554Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.077077Z",
          "shell.execute_reply": "2024-01-16T15:35:59.098495Z"
        },
        "trusted": true,
        "id": "qzMKa_ZnSeZo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NA values\n",
        "df = df.dropna()\n",
        "\n",
        "# Missing data analysis again\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.100663Z",
          "iopub.execute_input": "2024-01-16T15:35:59.100967Z",
          "iopub.status.idle": "2024-01-16T15:35:59.145913Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.100941Z",
          "shell.execute_reply": "2024-01-16T15:35:59.14506Z"
        },
        "trusted": true,
        "id": "gJ9dfr6qSeZp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop unused columns"
      ],
      "metadata": {
        "id": "0z3XJvIASeZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.147148Z",
          "iopub.execute_input": "2024-01-16T15:35:59.147581Z",
          "iopub.status.idle": "2024-01-16T15:35:59.164356Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.147547Z",
          "shell.execute_reply": "2024-01-16T15:35:59.163312Z"
        },
        "trusted": true,
        "id": "IngQ1E_jSeZq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class distribution"
      ],
      "metadata": {
        "id": "F3Vhyo5VSeZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distribution\n",
        "# 0 - Fake, 1 - Real\n",
        "df['label'].value_counts().plot.pie(autopct='%.2f')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.165594Z",
          "iopub.execute_input": "2024-01-16T15:35:59.165917Z",
          "iopub.status.idle": "2024-01-16T15:35:59.393392Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.16589Z",
          "shell.execute_reply": "2024-01-16T15:35:59.391746Z"
        },
        "trusted": true,
        "id": "5_6PpaNrSeZq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the graph we understand that we have balanced data.**"
      ],
      "metadata": {
        "id": "nIlKQzUBSeZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define X and y variables"
      ],
      "metadata": {
        "id": "6lC7v5Q4SeZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['label'])\n",
        "y = df['label']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.395345Z",
          "iopub.execute_input": "2024-01-16T15:35:59.395902Z",
          "iopub.status.idle": "2024-01-16T15:35:59.413463Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.395851Z",
          "shell.execute_reply": "2024-01-16T15:35:59.412078Z"
        },
        "trusted": true,
        "id": "M7_wOe1hSeZr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocab_size = Unique words in our Corpus (entire document)\n",
        "vocab_size = 10000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.41542Z",
          "iopub.execute_input": "2024-01-16T15:35:59.41597Z",
          "iopub.status.idle": "2024-01-16T15:35:59.425145Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.415926Z",
          "shell.execute_reply": "2024-01-16T15:35:59.423687Z"
        },
        "trusted": true,
        "id": "UM78Aps2SeZs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "messages = X.copy()\n",
        "\n",
        "# We have to reset index as we have used dropna() earlier, otherwise it will throw an error\n",
        "messages.reset_index(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.430933Z",
          "iopub.execute_input": "2024-01-16T15:35:59.431717Z",
          "iopub.status.idle": "2024-01-16T15:35:59.443807Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.431671Z",
          "shell.execute_reply": "2024-01-16T15:35:59.442254Z"
        },
        "trusted": true,
        "id": "y-i4hJZ9SeZs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "EWgXlmbpSeZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "lm = WordNetLemmatizer()\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "corpus = []\n",
        "for i in range(len(messages)):\n",
        "    review = re.sub('^a-zA-Z0-9',' ',messages['title'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review =[lm.lemmatize(x) for x in review if x not in stopwords]\n",
        "    review = \" \".join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:35:59.445801Z",
          "iopub.execute_input": "2024-01-16T15:35:59.446613Z",
          "iopub.status.idle": "2024-01-16T15:36:08.656552Z",
          "shell.execute_reply.started": "2024-01-16T15:35:59.446479Z",
          "shell.execute_reply": "2024-01-16T15:36:08.655659Z"
        },
        "trusted": true,
        "id": "thH0Ot5eSeZt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(len(sentence.split()) for sentence in corpus)\n",
        "\n",
        "print(\"Maximum sentence length:\", max_length)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:36:08.657702Z",
          "iopub.execute_input": "2024-01-16T15:36:08.657998Z",
          "iopub.status.idle": "2024-01-16T15:36:08.72367Z",
          "shell.execute_reply.started": "2024-01-16T15:36:08.657973Z",
          "shell.execute_reply": "2024-01-16T15:36:08.722682Z"
        },
        "trusted": true,
        "id": "7vpelbglSeZt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:36:08.725156Z",
          "iopub.execute_input": "2024-01-16T15:36:08.725476Z",
          "iopub.status.idle": "2024-01-16T15:36:08.731477Z",
          "shell.execute_reply.started": "2024-01-16T15:36:08.725449Z",
          "shell.execute_reply": "2024-01-16T15:36:08.730511Z"
        },
        "trusted": true,
        "id": "BUB-KlsjSeZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Vectorization"
      ],
      "metadata": {
        "id": "hNlj9M9wSeZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf =TfidfVectorizer()\n",
        "x=tf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:36:08.732719Z",
          "iopub.execute_input": "2024-01-16T15:36:08.733017Z",
          "iopub.status.idle": "2024-01-16T15:36:12.985542Z",
          "shell.execute_reply.started": "2024-01-16T15:36:08.732992Z",
          "shell.execute_reply": "2024-01-16T15:36:12.984713Z"
        },
        "trusted": true,
        "id": "RbOU4rxQSeZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"label\"]\n",
        "y.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:36:12.986678Z",
          "iopub.execute_input": "2024-01-16T15:36:12.98699Z",
          "iopub.status.idle": "2024-01-16T15:36:12.994068Z",
          "shell.execute_reply.started": "2024-01-16T15:36:12.986963Z",
          "shell.execute_reply": "2024-01-16T15:36:12.993119Z"
        },
        "trusted": true,
        "id": "h3FWI6kVSeZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting into train and test sets"
      ],
      "metadata": {
        "id": "S_kKXQSMSeZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:36:12.995171Z",
          "iopub.execute_input": "2024-01-16T15:36:12.995424Z",
          "iopub.status.idle": "2024-01-16T15:36:22.136867Z",
          "shell.execute_reply.started": "2024-01-16T15:36:12.995402Z",
          "shell.execute_reply": "2024-01-16T15:36:22.135698Z"
        },
        "trusted": true,
        "id": "qkRU1ugOSeZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:36:22.138254Z",
          "iopub.execute_input": "2024-01-16T15:36:22.138574Z",
          "iopub.status.idle": "2024-01-16T15:58:44.851508Z",
          "shell.execute_reply.started": "2024-01-16T15:36:22.138545Z",
          "shell.execute_reply": "2024-01-16T15:58:44.85028Z"
        },
        "trusted": true,
        "id": "Kek1ekxFSeZv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Metrics"
      ],
      "metadata": {
        "id": "XrI3CYXtSeZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=rf.predict(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:58:44.854333Z",
          "iopub.execute_input": "2024-01-16T15:58:44.854618Z",
          "iopub.status.idle": "2024-01-16T15:58:49.9321Z",
          "shell.execute_reply.started": "2024-01-16T15:58:44.854594Z",
          "shell.execute_reply": "2024-01-16T15:58:49.931155Z"
        },
        "trusted": true,
        "id": "MS_rlGvoSeZv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confusion matrix oluştur\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Matrisi görselleştirme\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, square=True)\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('Real Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T15:58:49.933281Z",
          "iopub.execute_input": "2024-01-16T15:58:49.933568Z",
          "iopub.status.idle": "2024-01-16T15:58:50.116436Z",
          "shell.execute_reply.started": "2024-01-16T15:58:49.933542Z",
          "shell.execute_reply": "2024-01-16T15:58:50.115512Z"
        },
        "trusted": true,
        "id": "FFckxUzNSeZw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Verilen confusion matrix\n",
        "conf_matrix = [[6226, 780],\n",
        "               [597, 6705]]\n",
        "\n",
        "# Hesaplamalar\n",
        "true_negatives = conf_matrix[0][0]\n",
        "false_positives = conf_matrix[0][1]\n",
        "false_negatives = conf_matrix[1][0]\n",
        "true_positives = conf_matrix[1][1]\n",
        "\n",
        "# Precision, Recall, F1-score ve Accuracy hesaplamaları\n",
        "precision = true_positives / (true_positives + false_positives)\n",
        "recall = true_positives / (true_positives + false_negatives)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
        "\n",
        "# Sonuçları yazdırma\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-score: {f1:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-16T16:02:12.792819Z",
          "iopub.execute_input": "2024-01-16T16:02:12.793285Z",
          "iopub.status.idle": "2024-01-16T16:02:12.802433Z",
          "shell.execute_reply.started": "2024-01-16T16:02:12.793253Z",
          "shell.execute_reply": "2024-01-16T16:02:12.801319Z"
        },
        "trusted": true,
        "id": "-Emyh9nbSeZw"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}